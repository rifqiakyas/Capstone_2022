{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee42d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57783738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = 'C:\\Sem 5\\Studi Independen\\Machine Learning\\CapstoneProject\\datasetBersih'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081365a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,           # normalisasi data\n",
    "                    horizontal_flip=True,     # data dapat berputar balik secara horizontal                  \n",
    "                    ) \n",
    "test_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7dd80cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11110 images belonging to 11 classes.\n",
      "Found 2783 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    color_mode= 'rgb', \n",
    "                                                    shuffle= True\n",
    "                                                    )\n",
    "test_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                  batch_size=64,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  color_mode= 'rgb', \n",
    "                                                  shuffle= True\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13baeabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST OF CLASSES  ['Bacterial_spot', 'Early_blight', 'Late_blight', 'Leaf_Mold', 'Septoria_leaf_spot', 'Spider_mites Two-spotted_spider_mite', 'Target_Spot', 'Tomato_Yellow_Leaf_Curl_Virus', 'Tomato_mosaic_virus', 'healthy', 'powdery_mildew']\n",
      "CLASS DICTIONARY  {'Bacterial_spot': 0, 'Early_blight': 1, 'Late_blight': 2, 'Leaf_Mold': 3, 'Septoria_leaf_spot': 4, 'Spider_mites Two-spotted_spider_mite': 5, 'Target_Spot': 6, 'Tomato_Yellow_Leaf_Curl_Virus': 7, 'Tomato_mosaic_virus': 8, 'healthy': 9, 'powdery_mildew': 10}\n",
      "Number of classes =  11\n"
     ]
    }
   ],
   "source": [
    "class_dict=train_generator.class_indices\n",
    "classes=list(class_dict.keys())\n",
    "print ('LIST OF CLASSES ', classes)\n",
    "print ('CLASS DICTIONARY ',class_dict)\n",
    "number_of_classes=len(classes) # this is the number of neurons in your top layer of the model\n",
    "print ('Number of classes = ', number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a59b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top= False, \n",
    "                                                               weights= \"imagenet\", \n",
    "                                                               input_shape= (224, 224, 3), \n",
    "                                                               pooling= 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60de2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),                                                # layer input untuk deep learning neural network \n",
    "    tf.keras.layers.Dense(11, activation= 'softmax')                                 # output layer 3 class\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6372d338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb3 (Functional)  (None, 1536)             10783535  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               393472    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11)                2827      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,179,834\n",
      "Trainable params: 11,092,531\n",
      "Non-trainable params: 87,303\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82cb0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='Adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1ee6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('accuracy') > 0.90 and logs.get('val_accuracy') > 0.90):\n",
    "            print(\"\\nAkurasi telah mencapai >90%!\") \n",
    "            self.model.stop_training = True \n",
    "callbacks = TestCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59cf213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4/4 - 128s - loss: 7.9191 - accuracy: 0.1914 - val_loss: 2.6735 - val_accuracy: 0.0977 - 128s/epoch - 32s/step\n",
      "Epoch 2/25\n",
      "4/4 - 118s - loss: 3.5821 - accuracy: 0.3086 - val_loss: 2.5289 - val_accuracy: 0.0977 - 118s/epoch - 29s/step\n",
      "Epoch 3/25\n",
      "4/4 - 115s - loss: 1.8390 - accuracy: 0.4531 - val_loss: 2.5153 - val_accuracy: 0.0977 - 115s/epoch - 29s/step\n",
      "Epoch 4/25\n",
      "4/4 - 115s - loss: 1.3407 - accuracy: 0.5547 - val_loss: 2.4457 - val_accuracy: 0.1211 - 115s/epoch - 29s/step\n",
      "Epoch 5/25\n",
      "4/4 - 114s - loss: 1.1075 - accuracy: 0.6250 - val_loss: 2.5743 - val_accuracy: 0.0938 - 114s/epoch - 28s/step\n",
      "Epoch 6/25\n",
      "4/4 - 115s - loss: 1.1685 - accuracy: 0.6367 - val_loss: 2.5209 - val_accuracy: 0.0938 - 115s/epoch - 29s/step\n",
      "Epoch 7/25\n",
      "4/4 - 113s - loss: 0.8895 - accuracy: 0.7305 - val_loss: 2.4675 - val_accuracy: 0.1055 - 113s/epoch - 28s/step\n",
      "Epoch 8/25\n",
      "4/4 - 113s - loss: 0.7621 - accuracy: 0.8008 - val_loss: 2.4220 - val_accuracy: 0.0938 - 113s/epoch - 28s/step\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nOSError: image file is truncated\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 239, in load\n    s = read(self.decodermaxblock)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\PngImagePlugin.py\", line 932, in load_read\n    cid, pos, length = self.png.read()\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\PngImagePlugin.py\", line 177, in read\n    length = i32(s)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\n\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\image_utils.py\", line 440, in load_img\n    img = img.convert(\"RGB\")\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 901, in convert\n    self.load()\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 245, in load\n    raise OSError(\"image file is truncated\") from e\n\nOSError: image file is truncated\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_31744]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12452\\1377168726.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history=model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m       \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nOSError: image file is truncated\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 239, in load\n    s = read(self.decodermaxblock)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\PngImagePlugin.py\", line 932, in load_read\n    cid, pos, length = self.png.read()\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\PngImagePlugin.py\", line 177, in read\n    length = i32(s)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\n\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"C:\\Users\\hanao\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\image_utils.py\", line 440, in load_img\n    img = img.convert(\"RGB\")\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 901, in convert\n    self.load()\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 245, in load\n    raise OSError(\"image file is truncated\") from e\n\nOSError: image file is truncated\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_31744]"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=4,                    \n",
    "      epochs=25,                            \n",
    "      validation_data=test_generator,       \n",
    "      verbose=2,\n",
    "      validation_steps=4,             \n",
    "      callbacks = [callbacks]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf424f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy Model')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
